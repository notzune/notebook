in [[Probability theory|probability theory]], the expected value (also known as the expectation, expectancy, expectation operator, mean, expectation value, or first [[Moment|moment]]) is a generalization of the [[Weighted arithmetic mean|weighted average]].

the expected value of a random variable with a finite number of outcomes is a weighted average of all possible outcomes. in the case of continuum of possible outcomes, the expectation is defined by [[Integral|integration]]. 

the expected value of a random variable $X$ is often denoted by E($X$), E$[X]$, or E$X$; with E often stylized as $E$ or $\mathbb{E}$. 